# ----------------------------------------------------
# Autogenerated from daas_layer_1.yaml
# ----------------------------------------------------
user_id: dummy_user
session_id: 2a9de718-58d9-4932-afe8-4dd0ffab7621 # system generated

# Power users can change it in non DaaS mode; Support types: px4 / mavlink / ardupilot / {specific drone models}
# Should be selected by our system based on time and sensor requirements, battery and range feasibility, etc
drones:
  count: 1
  flight_type: waypoint # choose between waypoint or indefinite period
  drone_models_list:
    - model: DJI_Matrice_300_RTK
      drone_flight_time: 110m
      controller: pid # Can be one of {pid/mpc/etc} ?? Can we provide sensible defaults for simulations?

time_duration: 60m # expected time for the trip by user -> check if time_duration is greater than drone_flight_time? If yes, 1st iteration: show error to user, 2nd iteration: use logic for drone handoff/switch
start_time: "17:00 IST" # time that user expect the drones to be available at "starting_point"

# Supported for: flight_type: waypoint
# Starting point for the trip
starting_point:
  - "38.8951"
  - "-77.0364"

# Refer to slide #9 in the MobiSys ppt for primitive assumptions taken here
# Assumption: Task happen in an ordered way -> 1 after the other
# TODO: Adding a async / sync flag should allow tasks to be running concurrently vs in an blocking ordered sense
# 1. Some tasks are inherently blocking, e.g., takeoff, land
# 2. go_to can be an async or a sync (requirements can be to start a dnn_task task while going to the waypoint)
tasks:
  # ---------------------------------- Due to the "flight_type: waypoint" mode ----------------------------------
  - type: takeoff
    height: 1.5 # m
    max_speed: 2 # m/s

  - type: go_to_waypoint
    lat: 38.8951
    long: -77.0364
    use_algorithm: none # none, some logic that we have (SR to think more)

  - type: move
    # these should be similar to the way AS2/UAL have envisioned
    direction: # choose from up, down, left, right, front, back, clockwise, anticlockwise
    velocity: # vx, vy, vz ...

  # ----------------------------------------------------

  # ---------------------------------- Part of the follow_me app bundle ----------------------------------
  - type: analysis
    app_bundle_id: dreamlab:follow_me # Unique identifier to which this task belongs to -> STRETCH (don't complicate for now): Future users can maybe create app bundles and submit to us (android appstore thingy)
    model_image: dreamlab:yolo_vip_v1 # docker image for the model -> this will allow Hermes to be a framework which is actually usable to other -> We can open source it then only
    control_priority: high # For DaaS concept -> How much drone control is allowed to a 3rd party DNN model; TBD: Refer AnDrone paper; TBD: Define the meaning of {high/med/low}
    sensors:
      - sensor_type: camera_primary
    fps: 10 # Process 1 outta every 3 frames; Assumption: This drone's camera has 30fps camera
    ocularone:
      edge: # Need to run a benchmark script for these numbers
        inf_times: 100
        utility: 100
        deadline: 200 # ms
        server: # add port number and IP
        post_processing_server: # add port number and IP
        # ...
      cloud: # Need to run a benchmark script for these numbers
        inf_times: 100
        utility: 100
        deadline: 300 # ms
        server: "https://aws.lamba.com/dream_lab/yolo_vip_1_dummy_url"
        post_processing_server: "https://aws.lamba.com/dream_lab/yolo_vip_1_dummy_url/post"
        # ...

  - type: analysis
    app_bundle_id: dreamlab:follow_me
    model_image: dreamlab:collision_avoidance_v1
    control_priority: high
    # TODO: How to fuse multiple sensor data? Put it in future work?
    sensors:
      - sensor_type: lidar
    fps: 15
    ocularone:
      edge: # Need to run a benchmark script for these numbers
        inf_times: 100
        utility: 100
        deadline: 200 # ms
        server: # add port number and IP
        post_processing_server: # add port number and IP
        # ...
      cloud: # Need to run a benchmark script for these numbers
        inf_times: 100
        utility: 100
        deadline: 300 # ms
        server: "https://aws.lamba.com/dream_lab/yolo_vip_1_dummy_url"
        post_processing_server: "https://aws.lamba.com/dream_lab/yolo_vip_1_dummy_url/post"
        # ...

  # Tries different heights and rotates 360, x number of times. (Idea taken from the Tello vip code)
  # Goal is to find the person -> analysis for yolo should override controls as soon as it detects a human.
  - type: rotate_in_position
    app_bundle_id: dreamlab:follow_me
    turns: 3
    max_speed: 0.5 # m/s
  # ------------------------------------------------------------------------------------------------------------------------

  # ---------------------------------- Part of the emergency_services app bundle ----------------------------------
  - type: analysis
    app_bundle_id: emergency_services
    model_image: dreamlab:bodypose_detection_v1
    control_priority: high
    sensors:
      - sensor_type: camera_primary
        max_fps: 10
    ocularone:
      enable: true
      compute: both # cloud_only / edge_only / both
      edge: # Need to run a benchmark script for these numbers
        utility: 100
        deadline: 200 # ms
        # ...
      cloud: # Need to run a benchmark script for these numbers
        utility: 100
        deadline: 300 # ms
        cloud_func_url: "https://aws.lamba.com/dream_lab/bodypose_1_dummy_url"
        # ...

  # ------------------------------------------------------------------------------------------------------------------------

  - type: return_to_base
    control_priority: high
    conditions:
      battery: 15 # As soon as the battery hits a certain percent -> Return to the closest base
      time: 60m
